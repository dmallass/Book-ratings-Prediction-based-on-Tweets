{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_names = ['Avatar', 'Get Shorty', 'Princess Bride', 'Goonies']\n",
    "movie_descriptions = [\n",
    "    'an epic science fiction film',\n",
    "    'a crime thriller comedy film; adapted from a book',\n",
    "    'a fantasy comedy adventure film; adapted from a book',\n",
    "    'an adventure comedy film'\n",
    "]\n",
    "# ratings: row=user, col=movie\n",
    "# All ratings are between 0 and 1, with 1 meaning the user really liked the movie.\n",
    "# A 0 value means the user has not rated the movie.\n",
    "ratings = csr_matrix([\n",
    "    [.1, 0, .2, 0],\n",
    "    [0, .9, 0, .3],\n",
    "    [.3, 0, .9, 0],\n",
    "    [0, 0, 0, .4],\n",
    "    [0, 0, .3, .4]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_term_matrix:\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.]\n",
      " [ 2.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.]\n",
      " [ 2.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.]]\n",
      "vocabulary\n",
      "[u'a' u'adapted' u'adventure' u'an' u'book' u'comedy' u'crime' u'epic'\n",
      " u'fantasy' u'fiction' u'film' u'from' u'science' u'thriller']\n"
     ]
    }
   ],
   "source": [
    "# Do not modify.\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b', dtype=np.float)\n",
    "movie_term_matrix = vectorizer.fit_transform(movie_descriptions)\n",
    "vocabulary = np.array(vectorizer.get_feature_names())\n",
    "print('movie_term_matrix:')\n",
    "print(movie_term_matrix.todense())\n",
    "print('vocabulary')\n",
    "print(vocabulary)\n",
    "\n",
    "# movie_term_matrix: value i,j is the frequency of term j in the description of movie i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.,  2.,  2.,  3.,  1.,  1.,  1.,  1.,  4.,  2.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def document_frequencies(movie_term_matrix):\n",
    "    \"\"\" Compute the number of different documents that each term appears in.\n",
    "    Params:\n",
    "      movie_term_matrix...csr_matrix where entry i,j is the number\n",
    "                          of times term j appears in document i\n",
    "    Returns:\n",
    "      a numpy array with one element per term in the vocabulary.\"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    #print movie_term_matrix.shape[1]\n",
    "    #movie_term_matrix.transpose()\n",
    "    #num_documents = movie_term_matrix.sum(axis =0).tolist()[0]\n",
    "    #print movie_term_matrix.todense()\n",
    "    #print num_documents\n",
    "    #for i in range(movie_term_matrix.shape[1]):\n",
    "        #print movie_term_matrix.data[i]\n",
    "        #X= movie_term_matrix.getcol(i)\n",
    "    #return np.array([len((movie_term_matrix.getcol(i)).nonzero()[0]) for i in range(movie_term_matrix.shape[1])])\n",
    "    #return np.array(Counter(num_documents))\n",
    "    l_list =[]\n",
    "    for i in range(movie_term_matrix.shape[1]):\n",
    "        count = 0\n",
    "        for j in range(movie_term_matrix.shape[0]):\n",
    "            if movie_term_matrix[j,i] != 0:\n",
    "                count +=1.0\n",
    "        l_list.append(count)\n",
    "    return np.array(l_list)\n",
    "    \n",
    "    \n",
    "dfs = document_frequencies(movie_term_matrix)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.        ,  0.        ,  0.5       ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "          0.25      ,  0.        ,  1.        ,  0.        ],\n",
       "        [ 1.        ,  0.5       ,  0.        ,  0.        ,  0.5       ,\n",
       "          0.33333333,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.25      ,  0.5       ,  0.        ,  1.        ],\n",
       "        [ 1.        ,  0.5       ,  0.5       ,  0.        ,  0.5       ,\n",
       "          0.33333333,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.25      ,  0.5       ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.5       ,  0.5       ,  0.        ,\n",
       "          0.33333333,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.25      ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(movie_term_matrix, dfs):\n",
    "    \"\"\" Create a new matrix that transforms movie_term_matrix using tfidf.\n",
    "    Simply divide each value by the document frequency for that term.\n",
    "    \n",
    "    Params:\n",
    "      movie_term_matrix...csr_matrix where entry i,j is the number\n",
    "                          of times term j appears in document i\n",
    "      dfs.................document frequencies for each term.\n",
    "    Returns:\n",
    "      A csr_matrix that is a copy of movie_term_matrix where value\n",
    "      i,j is divided by the document frequency of term j\"\"\"\n",
    "    ###TODO    \n",
    "    ###\n",
    "    X= movie_term_matrix.copy()\n",
    "    for i in range(movie_term_matrix.shape[1]):\n",
    "        d_freq = dfs[i]\n",
    "        for j in range(movie_term_matrix.shape[0]):\n",
    "             X[j,i] =  movie_term_matrix[j,i]/d_freq\n",
    "    return X\n",
    "\n",
    "# tfidf matrix: row=movie, col=term\n",
    "tfidf_matrix = tfidf(movie_term_matrix, dfs)\n",
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy   (0, 0)\t0.666666666667\n",
      "  (0, 1)\t0.333333333333\n",
      "  (0, 2)\t0.333333333333\n",
      "  (0, 3)\t0.166666666667\n",
      "  (0, 4)\t0.333333333333\n",
      "  (0, 5)\t0.222222222222\n",
      "  (0, 7)\t0.333333333333\n",
      "  (0, 8)\t0.666666666667\n",
      "  (0, 9)\t0.333333333333\n",
      "  (0, 10)\t0.25\n",
      "  (0, 11)\t0.333333333333\n",
      "  (0, 12)\t0.333333333333\n",
      "<bound method csr_matrix.toarray of <1x14 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.66666667,  0.33333333,  0.33333333,  0.16666667,  0.33333333,\n",
       "          0.22222222,  0.        ,  0.33333333,  0.66666667,  0.33333333,\n",
       "          0.25      ,  0.33333333,  0.33333333,  0.        ],\n",
       "        [ 0.75      ,  0.375     ,  0.125     ,  0.125     ,  0.375     ,\n",
       "          0.33333333,  0.75      ,  0.        ,  0.        ,  0.        ,\n",
       "          0.25      ,  0.375     ,  0.        ,  0.75      ],\n",
       "        [ 0.75      ,  0.375     ,  0.375     ,  0.125     ,  0.375     ,\n",
       "          0.25      ,  0.        ,  0.25      ,  0.75      ,  0.25      ,\n",
       "          0.25      ,  0.375     ,  0.25      ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.5       ,  0.5       ,  0.        ,\n",
       "          0.33333333,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.25      ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.42857143,  0.21428571,  0.5       ,  0.28571429,  0.21428571,\n",
       "          0.33333333,  0.        ,  0.        ,  0.42857143,  0.        ,\n",
       "          0.25      ,  0.21428571,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_user_profiles(ratings, tfidf_matrix):\n",
    "    \"\"\"\n",
    "    Create a user profile matrix by computing the weighted average of the tfidf\n",
    "    vectors of each movie he has rated. E.g., if a person has rated \n",
    "    one movie .2 with tfidf vector ([.1, .3]) and rated another movie\n",
    "    .6 with tfidf vector([.2, .4]), then the weighted average is:\n",
    "    [(.2*.1 + .6*.2) / (.2 + .6), (.2*.3 + .6*.4) / (.2 + .6)]\n",
    "    Params:\n",
    "      ratings........the user/movie ratings matrix\n",
    "      tfidf_matrix...the movie/term tfidf matrix\n",
    "    Returns:\n",
    "      A csr matrix where each row represents a user and the columns represent terms.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    user_ratings = []\n",
    "    M = ratings.shape[0]\n",
    "    N = movie_term_matrix.shape[1]\n",
    "    Y = lil_matrix((M,N))\n",
    "    #print M, N\n",
    "    X= ratings.copy()\n",
    "    #print X.todense()\n",
    "    #print X[0].nonzero()[1]\n",
    "    for i in range(X.shape[0]):\n",
    "        data = []\n",
    "        for j in range(X.indptr[i],X.indptr[i+1]):\n",
    "            row = (X.indices[j],X.data[j])\n",
    "            data.append(row)\n",
    "        user_ratings.append(data)\n",
    "    user_ratings_np = np.array(user_ratings)\n",
    "    #print user_ratings_np\n",
    "    count_users= len(user_ratings_np)\n",
    "    #print count_users\n",
    "    indptr = []\n",
    "    data_csr = []\n",
    "    for p in range(0,count_users):\n",
    "        indices  = []\n",
    "        for r in range(0,movie_term_matrix.shape[1]):\n",
    "            numr = 0\n",
    "            denr = 0\n",
    "            for q in range(len(user_ratings_np[p])):            \n",
    "                movie_id = user_ratings_np[p][q][0]\n",
    "                movie_rate = user_ratings_np[p][q][1]\n",
    "                tfidf_wt = tfidf_matrix[movie_id,r]\n",
    "                numr += movie_rate*tfidf_wt\n",
    "                denr += movie_rate\n",
    "            wtd_avg = numr/denr\n",
    "            Y[p,r] = wtd_avg\n",
    "            data_csr.append(wtd_avg)\n",
    "            indices.append(r)\n",
    "        #indptr.append(len(indices)-1) \n",
    "    return Y.tocsr()\n",
    "\n",
    "user_profiles = make_user_profiles(ratings, tfidf_matrix)\n",
    "dummy = csr_matrix([float(user_profiles[0,i]) for i in range(user_profiles.shape[1])])\n",
    "print \"dummy\" , dummy\n",
    "print user_profiles[0].toarray\n",
    "user_profiles.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def norm(vector):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of one row of a csr_matrix.\n",
    "    https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm\n",
    "    Input:\n",
    "      vector...one row from a csr_matrix\n",
    "    Returns:\n",
    "      a float, the Euclidean norm of the vector.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    vec = vector.toarray()\n",
    "    return np.sqrt(np.sum([vec[i]**2 for i in range(0,len(vec))]))\n",
    "    \n",
    "    \n",
    "norm(csr_matrix([3,4]))\n",
    "#norm(csr_matrix([3,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99451"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "def cosine(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors (rows from a csr_matrix).\n",
    "    https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    Params:\n",
    "      v1...one vector\n",
    "      v2...another vector\n",
    "    Returns:\n",
    "      a float representing the cosine similarity/\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    #numr = 0\n",
    "    #denr_1 =0\n",
    "    #denr_2 = 0\n",
    "    #v1_list = v1.data[1]\n",
    "    #v2_list = v2.data[1]\n",
    "    v1_array = v1.toarray()\n",
    "    v2_array = v2.toarray()\n",
    "    print v1.shape[1]\n",
    "    print v2.shape[1]\n",
    "    if(v1.shape[1] == v2.shape[1]):                     \n",
    "        numr = sum([x*y for x,y in zip(v1.data,v2.data)]) \n",
    "    else:\n",
    "        print \" error\"\n",
    "    denr_1 = np.sqrt(np.sum([v1_array[i]**2 for i in range(0,len(v1_array))]))\n",
    "    denr_2 = np.sqrt(np.sum([v2_array[i]**2 for i in range(0,len(v2_array))]))   \n",
    "    return numr/(denr_1*denr_2)\n",
    "                \n",
    "round(cosine(csr_matrix([2,4]), csr_matrix([3,8])), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 1.0]\n",
      "user prof   (0, 0)\t0.666666666667\n",
      "  (0, 1)\t0.333333333333\n",
      "  (0, 2)\t0.333333333333\n",
      "  (0, 3)\t0.166666666667\n",
      "  (0, 4)\t0.333333333333\n",
      "  (0, 5)\t0.222222222222\n",
      "  (0, 7)\t0.333333333333\n",
      "  (0, 8)\t0.666666666667\n",
      "  (0, 9)\t0.333333333333\n",
      "  (0, 10)\t0.25\n",
      "  (0, 11)\t0.333333333333\n",
      "  (0, 12)\t0.333333333333\n",
      "12\n",
      " error\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'numr' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-94ade49bae79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_profiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     return R\"\"\"\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_ratings_w_user_profiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-94ade49bae79>\u001b[0m in \u001b[0;36mpredict_ratings_w_user_profiles\u001b[1;34m(ratings, user_profiles, tfidf_matrix)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mtfidf_temp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"user prof\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_profiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \"\"\"for row in range(R.shape[0]):\n",
      "\u001b[1;32m<ipython-input-20-90ccfec54ab0>\u001b[0m in \u001b[0;36mcosine\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mdenr_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv1_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mdenr_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv2_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv2_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnumr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdenr_1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdenr_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'numr' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def predict_ratings_w_user_profiles(ratings, user_profiles, tfidf_matrix):\n",
    "    \"\"\"\n",
    "    Make a copy of the ratings matrix. Replace each 0 entry with a predicted score\n",
    "    based on user_profile. Specifically, the ratings of user i for movie j is the \n",
    "    cosine similarity between user i's profile and movie's j tfidf vector.\n",
    "    \n",
    "    Params:\n",
    "      ratings.........the user x movie ratings matrix.\n",
    "      user_profiles...the user x term profile matrix\n",
    "      tfidf_matrix....the move x term tfidf matrix\n",
    "    Returns:\n",
    "      a user x movie csr_matrix of ratings. It should be a copy of the original\n",
    "      ratings matrix, where 0 values have been replaced by the prediced rating.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    R = ratings.copy()\n",
    "    for row in range(R.shape[0]):\n",
    "        for col in range(R.shape[1]):\n",
    "            tfidf_temp =[]\n",
    "            for col_idx in range(tfidf_matrix.shape[1]):\n",
    "                if col_idx in user_profiles.indices[user_profiles.indptr[row]:user_profiles.indptr[row+1]]:\n",
    "                    tfidf_temp.append(tfidf_matrix[col,col_idx]) \n",
    "            print tfidf_temp\n",
    "            print \"user prof\", user_profiles[row]\n",
    "            R[row,col]=round(cosine(csr_matrix(tfidf_temp),user_profiles[row]),5)\n",
    "    return R\n",
    "    \"\"\"for row in range(R.shape[0]):\n",
    "        for col in range(R.shape[1]):            \n",
    "            #dummy_tfidf = csr_matrix([tfidf_matrix[col,col_idx])\n",
    "            #print \"tfidf\" , dummy_tfidf\n",
    "            print \"user prof\", user_profiles[row]\n",
    "            R[row,col]=round(cosine(tfidf_matrix[col],user_profiles[row]),5)\n",
    "    return R\"\"\"\n",
    "predicted = predict_ratings_w_user_profiles(ratings, user_profiles, tfidf_matrix)\n",
    "predicted.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
