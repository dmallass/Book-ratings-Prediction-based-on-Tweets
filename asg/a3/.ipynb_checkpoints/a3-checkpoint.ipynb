{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import hashlib\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tarfile\n",
    "from urllib import urlretrieve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\" Download and unzip data.\"\"\"\n",
    "    urlretrieve('https://www.dropbox.com/s/xk4glpk61q3qrg2/imdb.tgz?dl=1', 'imdb.tgz')\n",
    "    tar = tarfile.open(\"imdb.tgz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    \n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirectories are:['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Here is the path to the data directory.\n",
    "path = 'data'\n",
    "print('subdirectories are:' + str(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \"\"\" Return a list of file names in this directory that end in .txt \n",
    "    The list should be sorted alphabetically by file name.\n",
    "    Params:\n",
    "        path....a directory containing .txt review files.\n",
    "    Returns:\n",
    "        a list of .txt file names, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \"\"\"for files in os.listdir(path):\n",
    "        for file1 in files:            \n",
    "            if file1.endswith(\".txt\"):\n",
    "                result += file1\"\"\"\n",
    "    result  = [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.txt')]\n",
    "    return sorted(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 200 positive and 200 negative training files\n",
      "first positive file: data\\train\\pos\\10057_9.txt\n",
      "first negative file: data\\train\\neg\\10108_1.txt\n"
     ]
    }
   ],
   "source": [
    "pos_train_files = get_files(path + os.sep + 'train' + os.sep + 'pos')\n",
    "neg_train_files = get_files(path + os.sep + 'train' + os.sep + 'neg')\n",
    "all_train_files = pos_train_files + neg_train_files\n",
    "\n",
    "print('found %d positive and %d negative training files' %\n",
    "      (len(pos_train_files), len(neg_train_files)))\n",
    "print('first positive file: %s' % pos_train_files[0])\n",
    "print('first negative file: %s' % neg_train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 and last 3 labels are: [1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def get_true_labels(file_names):\n",
    "    \"\"\"Return a *numpy array* of ints for the true sentiment labels of each file.\n",
    "    1 means positive, 0 means negative. Use the name of the file to determine\n",
    "    the true label.\n",
    "    Params:\n",
    "        file_names....a list of .txt file paths, e.g., data/train/pos/10057_9.txt\n",
    "    Returns:\n",
    "        a numpy array of 1 or 0 values corresponding to each element\n",
    "        of file_names, where 1 indicates a positive review, and 0\n",
    "        indicates a negative review.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    array = np.empty(shape=[0,len(file_names)] , dtype='int')\n",
    "    names =[]\n",
    "    for item in file_names:\n",
    "        path_names = item.split(os.sep)\n",
    "        if path_names[2] == 'pos':\n",
    "            names.append(1)\n",
    "        else :\n",
    "            names.append(0)  \n",
    "    array = np.append(array,names)\n",
    "         \n",
    "    \n",
    "    #array = np.concatenate(array,names)\n",
    "    #numpy_array = np.array(names)\n",
    "    return array\n",
    "    \n",
    "    \n",
    "labels = get_true_labels(all_train_files)\n",
    "#print labels\n",
    "#print len(labels)\n",
    "print('first 3 and last 3 labels are: %s' % str(labels[[1,2,3,-3,-2,-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"This is a great film!! The first time I saw it I thought it was absorbing from start to finish and I still do now. I may not have seen the play, but even if I had it wouldn't stop me thinking that the film is just as good.\""
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's what a positive review looks like.\n",
    "def file2string(filename):\n",
    "    return io.open(filename, encoding='utf8').readlines()[0]\n",
    "    \n",
    "file2string(pos_train_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'how',\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " 'an_underscore',\n",
       " 'is',\n",
       " 'not',\n",
       " 'really',\n",
       " 'punctuation']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "def tokenize(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is removed. Note that\n",
    "    underscore (_) is not considered punctuation.\n",
    "    UPDATE: To be more specific, a token is a sequence of \n",
    "    alphanumeric characters, i.e., [A-Za-z0-9_]. Non-ascii characters\n",
    "    are not considered to be part of tokens.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    #toker = RegexpTokenizer(r'((?<=[^\\w\\s])\\w(?=[^\\w\\s])|(\\W))+', gaps=True)\n",
    "    return re.sub('\\W+', ' ', text).lower().split()\n",
    "    #print toker.tokenize(text)\n",
    "    \n",
    "\n",
    "tokenize(\"Hi! How's it going??? an_underscore is not *really* punctuation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix represents 400 documents with 10710 features\n",
      "first doc has terms:\n",
      "[128, 170, 202, 253, 260, 312, 355, 439, 504, 514, 560, 673, 683, 702, 750, 860, 869, 961, 985, 1013, 1222, 1254, 1312, 1341, 1403, 1444, 1451, 1469, 1504, 1658, 1665, 1743, 2465, 2537, 2996, 3109, 3206, 3229, 3356, 3368, 3515, 3634, 3706, 3716, 3759, 3810, 3926, 4015, 4059, 4061, 4087, 4139, 4205, 4207, 4222, 4309, 4366, 4384, 4412, 4435, 4472, 4510, 4524, 4631, 4690, 4757, 4798, 5062, 5074, 5225, 5274, 5287, 5289, 5312, 5360, 5418, 5609, 5610, 5646, 5693, 5761, 5888, 5932, 5948, 6116, 6243, 6258, 6294, 6424, 6440, 6579, 6620, 6676, 6696, 6860, 6942, 7094, 7626, 8052, 8248, 8336, 8341, 8474, 8767, 8988, 9204, 9412, 9436, 9440, 9505, 9508, 9523, 9550, 9558, 9634, 9684, 9690, 9835, 9855, 9857, 10047, 10337, 10353, 10431, 10441, 10446, 10448, 10519]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "def do_vectorize(filenames, tokenizer_fn=tokenize, min_df=1,\n",
    "                 max_df=1., binary=True, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Convert a list of filenames into a sparse csr_matrix, where\n",
    "    each row is a file and each column represents a unique word.\n",
    "    Use sklearn's CountVectorizer: http://goo.gl/eJ2PJ5\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "    Return:\n",
    "        A tuple (X, vec), where X is the csr_matrix of feature vectors,\n",
    "        and vec is the CountVectorizer object.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    \n",
    "    vectorizer = CountVectorizer(input='filename', encoding='utf-8', tokenizer=tokenizer_fn, min_df=min_df,max_df=max_df, binary=binary, ngram_range= ngram_range ,analyzer=u'word',dtype=int)\n",
    "    X = vectorizer.fit_transform(filenames)\n",
    "    return (X,vectorizer)\n",
    "matrix, vec = do_vectorize(all_train_files)\n",
    "print ('matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))\n",
    "print('first doc has terms:\\n%s' % (str(sorted(matrix[0].nonzero()[1]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first shuffled document data\\train\\pos\\5140_10.txt has label 1 and terms: [98, 170, 355, 384, 514, 720, 750, 780, 1225, 2234, 3356, 3682, 3916, 4015, 4397, 4690, 4798, 5074, 5080, 5764, 5948, 6579, 6782, 6950, 7899, 8186, 8587, 9045, 9508, 9550, 9609, 9827, 10003, 10421, 10640]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify. This is to randomize the order of the documents, but\n",
    "# in a way that is consistent across platforms.\n",
    "# See: http://stackoverflow.com/a/18992474/1756896\n",
    "# You should run this block once to get the shuffled data.\n",
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield ord(c)\n",
    "\n",
    "def repeatable_shuffle(X, y, filenames):\n",
    "    r = repeatable_random(42) \n",
    "    indices = sorted(range(X.shape[0]), key=lambda x: next(r))\n",
    "    return X[indices], y[indices], np.array(filenames)[indices]\n",
    "\n",
    "X, y, filenames = repeatable_shuffle(matrix, labels, all_train_files)\n",
    "\n",
    "print('first shuffled document %s has label %d and terms: %s' % \n",
    "      (filenames[0], y[0], sorted(X[0].nonzero()[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not modify. This creates a LogsticRegression object, which\n",
    "# you will use in the do_cross_validation method below.\n",
    "def get_clf():\n",
    "    return LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 accuracy=0.7125\n",
      "fold 1 accuracy=0.7750\n",
      "fold 2 accuracy=0.7750\n",
      "fold 3 accuracy=0.7250\n",
      "fold 4 accuracy=0.7125\n",
      "average cross validation accuracy=0.7400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "def do_cross_validation(X, y, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform n-fold cross validation, calling get_clf() to train n\n",
    "    different classifiers. Use sklearn's KFold class: http://goo.gl/wmyFhi\n",
    "    Be sure not to shuffle the data, otherwise your output will differ.\n",
    "    Params:\n",
    "        X.........a csr_matrix of feature vectors\n",
    "        y.........the true labels of each document\n",
    "        n_folds...the number of folds of cross-validation to do\n",
    "        verbose...If true, report the testing accuracy for each fold.\n",
    "    Return:\n",
    "        the average testing accuracy across all folds.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    cv = KFold(len(y), n_folds)    \n",
    "    accuracies = []\n",
    "    fold = 0\n",
    "    #accuracy = 1. * len([1 for tr, pr in zip(y[test_ind], predictions) if tr == pr]) / len(y[test_ind]))\n",
    "    for train_ind, test_ind in cv:  \n",
    "        model = get_clf()\n",
    "        model.fit(X[train_ind], y[train_ind])\n",
    "        predictions = model.predict(X[test_ind])\n",
    "        accuracies.append(accuracy_score(y[test_ind], predictions))\n",
    "        if verbose == True:\n",
    "            print ('fold %d accuracy=%.4f' %(fold,accuracy_score(y[test_ind], predictions)))\n",
    "        fold += 1\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy\n",
    "print('average cross validation accuracy=%.4f' %\n",
    "      do_cross_validation(X, y, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_expt(filenames, y, tokenizer_fn=tokenize,\n",
    "            min_df=1, max_df=1., binary=True,\n",
    "            ngram_range=(1,1), n_folds=5):\n",
    "    \"\"\"\n",
    "    Run one experiment, which consists of vectorizing each file,\n",
    "    performing cross-validation, and returning the average accuracy.\n",
    "    You should call do_vectorize and do_cross_validation here.\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        y...............the true sentiment labels for each file\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "        n_folds.........The number of cross-validation folds to use.\n",
    "    Returns:\n",
    "        the average cross validation testing accuracy.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    matrix, vec = do_vectorize(filenames,tokenizer_fn=tokenizer_fn, min_df=min_df, max_df=max_df, binary=binary, ngram_range=(1,1))\n",
    "    avg_accuracy = do_cross_validation(matrix, y,n_folds)\n",
    "    return avg_accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using default settings: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('accuracy using default settings: %.4g' % do_expt(filenames, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEQCAYAAACugzM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHBRmZtaQg8LMzBpyUJiZWUP/H3lwp7zxIaPeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19864f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.69999999999999996, 0.73999999999999999, 0.745, 0.75250000000000006]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def compare_n_folds(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of n_folds parameter in the do_expt \n",
    "    function to be in [2,5,10,20]. For each setting, call do_expt and \n",
    "    store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per fold.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    n_folds = [2,5,10,20]\n",
    "    result_accuracy = []\n",
    "    for fold in n_folds:        \n",
    "        result_accuracy.append(do_expt(filenames,y, n_folds=fold))\n",
    "    plt.plot(n_folds,result_accuracy, 'bo-', label ='n-fold accuracy')\n",
    "    plt.xlabel('n_folds')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    return result_accuracy\n",
    "compare_n_folds(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TO-DO\n",
    "Why do you think accuracy increases as the number of folds increases?\n",
    "\n",
    "The smaller the number of folds,larger will be the test and training set size and smaller is the number of times a set can become training set. For eg, if number of folds = 5, a set will be trained 4 times whereas in number of folds = 10, the size of training set will be smaller and it will be used for training 9 times. Hence acccuray increases when we make it more fine grained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73999999999999999, 0.69999999999999996]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_binary(filenames, y):\n",
    "    \"\"\"\n",
    "    How does the binary parameter affect results? \n",
    "    Call do_expt twice, once with binary=True, and once with binary=False.\n",
    "    Return the average accuracies for each. Use the default parameters for the\n",
    "    remaining arguments in do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies. The first entry\n",
    "        is for binary=True, the second is for binary=False.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    result_accuracy = []\n",
    "    result_accuracy.append(do_expt(filenames,y, binary=True))\n",
    "    result_accuracy.append(do_expt(filenames,y, binary=False))\n",
    "    return result_accuracy    \n",
    "          \n",
    "compare_binary(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##TO-DO\n",
    "Why do you think using binary feature vectors does better than using term frequency?\n",
    "\n",
    "In this example, we only have 2 classes and all of the unique words are used as attributes. Setting binary equals to True will result in all non-zero counts to one. If we choose word frequency as your attribute, then we will take the word frequency as the attribute and assign '2' if that word occurs twice in your text, and '0' if not, or '1' if that word occurs only once. The best representation depends on the problem. If text are not long, usually binary representation is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " '!',\n",
       " 'how',\n",
       " \"'\",\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'an_underscore',\n",
       " 'is',\n",
       " 'not',\n",
       " '*',\n",
       " 'really',\n",
       " '*',\n",
       " 'punctuation',\n",
       " '.']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk import word_tokenize\n",
    "def tokenize_with_punct(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is kept as separate tokens.\n",
    "    Note that underscore (_) is not considered punctuation.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    text.encode(\"utf-8\")\n",
    "    #return re.findall(r'[.?!\\'*\\\"#$%&\\)\\xe9\\(,+-@;`:<=>\\[\\]^\\{\\}]|\\w+', text.lower())\n",
    "    return re.findall(r\"[\\w]+|[^\\s\\w]\",text.lower())\n",
    "\n",
    "tokenize_with_punct(\"Hi! How's it going??? an_underscore is not *really* punctuation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_good',\n",
       " 'not_.',\n",
       " 'in',\n",
       " 'fact',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_even',\n",
       " 'not_really',\n",
       " 'a',\n",
       " 'movie',\n",
       " '.']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_with_not(text):\n",
    "    \"\"\"Does the same thing as tokenize_with_punct, with the following difference:\n",
    "    whenever the term 'not' appears, change the two subsequent tokens to have the prefix\n",
    "    'not_' prior to the token. See the example below. You may call \n",
    "    tokenize_with_punct as a subroutine.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    #tokens = re.findall(r'[.?!\\'*\\\"#$%&\\)\\xe9\\(,+-@;`:<=>\\[\\]^\\{\\}]|\\w+', text.lower())\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\",text.lower())\n",
    "    for i in range(len(tokens)):\n",
    "        if (tokens[i] == 'not') and (i < len(tokens)-2):\n",
    "            tokens[i+1] = ('not_'+tokens[i+1])\n",
    "            tokens[i+2] = ('not_'+tokens[i+2])\n",
    "        elif (tokens[i] == 'not') and (i == len(tokens)-2):\n",
    "            tokens[i+1] = ('not_'+tokens[i+1])\n",
    "    return tokens\n",
    "\n",
    "tokenize_with_not(\"This movie is not good. In fact, it is not even really a movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "énot the",
      "fiancéée-\n",
      "\r",
      "of not Henrié \n",
      "tokenize: not, the, fianc, e, of, not, henri\n",
      "tokenize_with_punct: é, not, the, ",
      ", fianc, é, é, e, -, of, not, henri, é\n",
      "tokenize_with_not: é, not, not_the, not_",
      ", fianc, é, é, e, -, of, not, not_henri, not_é\n"
     ]
    }
   ],
   "source": [
    "# To keep things simple, we'll pretend that non-ascii \n",
    "# characters are punctuation.\n",
    "#nonascii_string = u'not the fiancée of not Henri'\n",
    "nonascii_string = u'énot the\\x85fiancéée-\\n\\rof not Henrié '\n",
    "print nonascii_string\n",
    "print('tokenize: %s' % \n",
    "      ', '.join(tokenize(nonascii_string)))\n",
    "print('tokenize_with_punct: %s' %\n",
    "      ', '.join(tokenize_with_punct(nonascii_string)))\n",
    "print('tokenize_with_not: %s' %\n",
    "      ', '.join(tokenize_with_not(nonascii_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73999999999999999, 0.74499999999999988, 0.74749999999999994]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_expt(all_train_files, y):\n",
    "    \"\"\"\n",
    "    How does the tokenizer affect results? \n",
    "    Call do_expt three times, using three different tokenizers:\n",
    "    1- tokenize\n",
    "    2- tokenize_with_punct\n",
    "    3- tokenize_with_not\n",
    "    Return the average cross-validation accuracy for each approach,\n",
    "    in the above order. Use the default parameters for all other \n",
    "    arguments to do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies for each tokenizer.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    r_accuracy = []\n",
    "    r_accuracy.append(do_expt(filenames,y, tokenizer_fn=tokenize))\n",
    "    r_accuracy.append(do_expt(filenames,y, tokenizer_fn=tokenize_with_punct))\n",
    "    r_accuracy.append(do_expt(filenames,y, tokenizer_fn=tokenize_with_not))\n",
    "    return r_accuracy     \n",
    "\n",
    "tokenizer_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZG8KYmIiEje/j9ObT/+y/aliAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188183c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.74749999999999994,\n",
       " 0.76000000000000001,\n",
       " 0.75000000000000011,\n",
       " 0.74249999999999994,\n",
       " 0.74999999999999989,\n",
       " 0.74249999999999994,\n",
       " 0.74749999999999994,\n",
       " 0.73750000000000004,\n",
       " 0.72750000000000004,\n",
       " 0.73000000000000009]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def min_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of min_df parameter in the do_expt \n",
    "    function to be ints in the range (1,10) (inclusive). For each setting,\n",
    "    call do_expt and store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function, except that the tokenizer\n",
    "    should be tokenize_with_not.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per min_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    r_accuracy = []\n",
    "    for min_value in range(1,11):\n",
    "        r_accuracy.append(do_expt(filenames,y, min_df=min_value, tokenizer_fn=tokenize_with_not))\n",
    "    plt.plot(range(1,11),r_accuracy, 'bo-', label ='min_df accuracy')\n",
    "    plt.xlabel('min_df')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()    \n",
    "    return r_accuracy\n",
    "\n",
    "min_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TO-DO\n",
    "The best accuracy occurs when min_df=2. Why do you think this is better than setting min_df=1.\n",
    "\n",
    "min_df represents --> When building the vocabulary ignore terms that have a document frequency strictly lower than the given \n",
    "threshold. So with min_df =1, it could include rarely used terms and with min_df =2, we are limiting the terms to more \n",
    "frequent terms than min_df =1. So the results would be more accurate. With min_df =1, we can avoid rarely used terms which are of \n",
    "no interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9fd4160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.76000000000000001,\n",
       " 0.75250000000000006,\n",
       " 0.76749999999999996,\n",
       " 0.76000000000000001,\n",
       " 0.75250000000000006,\n",
       " 0.74999999999999989,\n",
       " 0.77000000000000013,\n",
       " 0.76250000000000007,\n",
       " 0.75749999999999995,\n",
       " 0.76000000000000001]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of max_df parameter in the do_expt \n",
    "    function to be one of [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.].\n",
    "    For each setting, call do_expt and store the resulting accuracy.\n",
    "    Plot the accuracies for each setting. Also return the list of accuracies.\n",
    "    Use the default value for all other arguments to the do_expt function,\n",
    "    except that the tokenizer=tokenize_with_not and min_df=2.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per max_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    r_accuracy = []\n",
    "    max_df_list = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
    "    for max_df_val in max_df_list:\n",
    "        r_accuracy.append(do_expt(filenames,y, tokenizer_fn=tokenize_with_not, min_df=2, max_df=max_df_val))\n",
    "    plt.plot(range(1,11),r_accuracy, 'bo-', label ='max_df accuracy')\n",
    "    plt.xlabel('max_df')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()     \n",
    "    return r_accuracy        \n",
    "    \n",
    "max_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train our final classifier using our best settings.\n",
    "X, vec = do_vectorize(filenames, tokenizer_fn=tokenize_with_not,\n",
    "                      binary=True, min_df=2, max_df=.7)\n",
    "clf = get_clf()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(1L, 4735L)\n"
     ]
    }
   ],
   "source": [
    "print type(clf.coef_)\n",
    "print clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30213187 -0.31130512 -0.01907301 -0.13229153  0.05602346  0.16798958\n",
      " -0.11328428  0.0352349  -0.13077808 -0.05752335]\n",
      "[u'!', u'\"', u'#', u'$', u'%', u'&', u'(', u')', u'*', u'+']\n"
     ]
    }
   ],
   "source": [
    "# Here are the first 10 coefficients.\n",
    "print(clf.coef_[0][:10])\n",
    "# The features corresponding to them can be found using the vectorizer's get_feature_names method.\n",
    "print(vec.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-345-da477b4c1cab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mpos_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'top positive coefs: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_coef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'top negative coefs: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_coef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-345-da477b4c1cab>\u001b[0m in \u001b[0;36mget_top_coefficients\u001b[1;34m(clf, vec, n)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mvocab_terms\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "def get_top_coefficients(clf, vec, n=10):\n",
    "    \"\"\" Get the top n coefficients for each class (positive/negative).\n",
    "    Params:\n",
    "        clf...a LogisticRegression object that has already been fit to data.\n",
    "        vec...a CountVectorizer\n",
    "        n.....the number of features to print per class.\n",
    "    Returns:\n",
    "        Two lists of tuples. The first list containts the top terms for the positive\n",
    "        class. Each entry is a tuple of (string, float) pairs, where\n",
    "        string is the feature name and float is the coefficient.\n",
    "        The second list is the same but for the negative class.\n",
    "        In each list, entries should be sorted in descending order of \n",
    "        absolute value.\"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    vocab= np.array(vec.get_feature_names())\n",
    "    #vocab_terms= np.array([x[0] for x in sorted(vocab.items(), key=lambda x: x[1])])\n",
    "    \n",
    "    coef = clf.coef_[0]\n",
    "    coef_ind = np.argsort(coef)\n",
    "    desc_ind = coef_ind[::-1][:n]\n",
    "    asc_ind = coef_ind[:n]\n",
    "    \n",
    "    t_top_coef = coef[desc_ind]\n",
    "    b_coef = coef[asc_ind]\n",
    "    \n",
    "    pos = [(fn,coef_val) for fn, coef_val in zip(vocab[desc_ind],t_top_coef)]\n",
    "    neg = [(fn,coef_val) for fn, coef_val in zip(vocab[asc_ind],b_coef)]\n",
    "    \n",
    "    return pos,neg\n",
    "pos_coef, neg_coef = get_top_coefficients(clf, vec, n=5)\n",
    "print('top positive coefs: %s' % str(pos_coef))\n",
    "print('top negative coefs: %s' % str(neg_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify.\n",
    "pos_test_files = get_files(path + os.sep + 'test' + os.sep + 'pos')\n",
    "neg_test_files = get_files(path + os.sep + 'test' + os.sep + 'neg')\n",
    "all_test_files = pos_test_files + neg_test_files\n",
    "# Note that we call .transform, not .fit_transform, since we \n",
    "# don't want to learn a new vocabulary.\n",
    "X_test = vec.transform(all_test_files)\n",
    "y_test = np.array([1] * len(pos_test_files) + [0] * len(neg_test_files))\n",
    "print('X_test represents %d documents with %d features' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('y_test has %d positive and %d negative labels' % (len(np.where(y_test==1)[0]),\n",
    "                                                          len(np.where(y_test==0)[0])))\n",
    "print('first testing file is %s' % all_test_files[0])\n",
    "print('last testing file is %s' % all_test_files[-1])\n",
    "print('testing accuracy=%.4g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify.\n",
    "def index_of_term(vec, term):\n",
    "    \"\"\" This returns the column index corresponding to this term.\"\"\"\n",
    "    return vec.get_feature_names().index(term)\n",
    "\n",
    "index_of_term(vec, 'film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_after_removing_features(X, y, vec, features_to_remove):\n",
    "    \"\"\"\n",
    "    Set to 0 the columns of X corresponding to the terms in features_to_remove. \n",
    "    Then, train a new classifier on X and y and return the result.\n",
    "    Params:\n",
    "        X....................the training matrix\n",
    "        y....................the true labels for each row in X\n",
    "        features_to_remove...a list of strings (entries in the vocabulary) that\n",
    "                             should be removed from X\n",
    "    Returns:\n",
    "       The classifier fit on the modified X data.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###    \n",
    "    for term in features_to_remove:\n",
    "        Col_index = vec.get_feature_names().index(term)\n",
    "        for rows in range(0,X.shape[0]):\n",
    "            X[rows,Col_index]=0           \n",
    "    clf = get_clf()\n",
    "    clf.fit(X,y)\n",
    "    return clf\n",
    "    \n",
    "clf = train_after_removing_features(X.copy(), y, vec, ['film'])\n",
    "print('testing accuracy=%.5g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_errors(X_test, y_test, filenames, clf, n=10):\n",
    "    \"\"\"\n",
    "    Use clf to predict the labels of the testing data in X_test. \n",
    "    We want to find incorrectly predicted documents. Furthermore, we want to look at those \n",
    "    where the probability of the incorrect label, according to the classifier, is highest.\n",
    "    Use the .predict_proba method of the classifier to get the probabilities of\n",
    "    each class label. Return the n documents that were misclassified, sorted by the\n",
    "    probability of the incorrect label. The returned value is a list of dicts, defined below.\n",
    "    Params:\n",
    "        X_test......the testing matrix\n",
    "        y_test......the true labels for each testing document\n",
    "        filenames...the filenames for each testing document\n",
    "        clf.........a trained LogisticRegression object\n",
    "        n...........the number of errors to return\n",
    "    Returns:\n",
    "        A list of n dicts containing the following key/value pairs:\n",
    "           index: the index of this document (in the filenames array)\n",
    "           probas: a numpy array containing the probability of class 0 and 1\n",
    "           truth: the true label\n",
    "           predicted: the predicted label\n",
    "           filename: the path to the file for this document\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    predicted = clf.predict(X_test)\n",
    "    predicted_proba = clf.predict_proba(X_test)    \n",
    "    list_dict =[]\n",
    "    for i in range(len(predicted)):\n",
    "        e_dict ={}\n",
    "        probability = predicted_proba[i][predicted[i]]\n",
    "        # If we're very wrong.\n",
    "        if predicted[i] != y_test[i] :\n",
    "            e_dict['filename']= filenames[i]\n",
    "            e_dict['index']= i\n",
    "            e_dict['probas'] = predicted_proba[i]\n",
    "            e_dict['truth'] = y_test[i]\n",
    "            e_dict['predicted'] = predicted[i]\n",
    "            e_dict['sort_prob_inc_label']=probability\n",
    "            list_dict.append(e_dict)\n",
    "    list_dict_sorted = sorted(list_dict, key = lambda x: x['sort_prob_inc_label'], reverse =True)[:n]\n",
    "    return list_dict_sorted\n",
    "errors = get_top_errors(X_test, y_test, all_test_files, clf)\n",
    "errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(dict.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a document, find the term in it that is most strongly associated\n",
    "# with a given class label, according to a trained classifier.\n",
    "def most_predictive_term_in_doc(instance, clf, class_idx):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        instance....one row in the X csr_matrix, corresponding to a document.\n",
    "        clf.........a trained LogisticRegression classifier\n",
    "        class_idx...0 or 1. The class for which we should find the most \n",
    "                    predictive term in this document.\n",
    "    Returns:\n",
    "        The index corresponding to the term that appears in this instance\n",
    "        and has the highest coefficient for class class_idx.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    coef = clf.coef_[0]\n",
    "    term_indices = sorted(instance.indices, key =lambda X : coef[X])\n",
    "    return (term_indices[0] if class_idx == 0 else term_indices[-1])\n",
    "    \n",
    "    \n",
    "neg_idx = most_predictive_term_in_doc(X_test[0], clf, 0)\n",
    "pos_idx = most_predictive_term_in_doc(X_test[0], clf, 1)\n",
    "print('for document %s, the term most predictive of class 0 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[neg_idx], neg_idx))\n",
    "print('for document %s, the term most predictive of class 1 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[pos_idx], pos_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_contexts(filename, term, window=5):\n",
    "    \"\"\"\n",
    "    Find all context windows in which this term appears in this file.\n",
    "    You should use tokenize_with_not to tokenize this file. \n",
    "    \n",
    "    Params:\n",
    "        filename....the filename for this document.\n",
    "        term........the term to find\n",
    "        window......return this many tokens to the left and this many tokens to\n",
    "                    the right of every occurrence of term in this document\n",
    "    Returns:\n",
    "        a list of strings. Each string contains the matched context window.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    positions=[]\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "    t_data = ' '.join(data)\n",
    "    tokens=tokenize_with_not(t_data)\n",
    "    for pos in range(len(tokens)):\n",
    "        if tokens[pos]==term:\n",
    "            positions.append(pos)\n",
    "    contexts=[]\n",
    "    for k in positions:\n",
    "        c_window =\"\"\n",
    "        w_length = 1+(2*window)\n",
    "        for n in range(w_length):\n",
    "            if((k-window+n)<len(tokens)):\n",
    "                c_window=c_window+tokens[k-window+n]+\" \"\n",
    "        contexts.append(c_window)\n",
    "    return contexts\n",
    "    \n",
    "# Here are some sample outputs on the first test document:\n",
    "print('\"no\" context with window 3: %s' % find_contexts(all_test_files[0], 'no', 3))\n",
    "print('\"no\" context with window 5: %s' % find_contexts(all_test_files[0], 'no', 5))\n",
    "print('\"best\" context: %s' % find_contexts(all_test_files[0], 'best'))\n",
    "print('\"a\" contexts: %s' % find_contexts(all_test_files[0], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify. This will use your code above to print the top errors.\n",
    "def print_errors(errors, clf, X, vec, window=5):\n",
    "    for error in errors:\n",
    "        #print vec.get_feature_names()[most_predictive_term_in_doc(X_test[error['index']], clf, error['predicted'])]\n",
    "        fidx = most_predictive_term_in_doc(X[error['index']], clf, error['predicted'])\n",
    "        term = vec.get_feature_names()[fidx]\n",
    "        print('document %s misclassified as %d' % (error['filename'], error['predicted']))\n",
    "        print('%s appears here:' % (term))\n",
    "        print(find_contexts(error['filename'], term, window))\n",
    "        print('')\n",
    "        \n",
    "print_errors(errors, clf, X_test, vec, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify.\n",
    "import json\n",
    "outf = open('output.txt', 'wt')\n",
    "clf.fit(X, y)\n",
    "\n",
    "json.dump({\n",
    "           'find_contexts': find_contexts(all_test_files[10], 'its', 10),\n",
    "           'pred_term': most_predictive_term_in_doc(X_test[10], clf, 1),\n",
    "           'top_errors': str(get_top_errors(X_test, y_test, all_test_files, clf)[0].items()),\n",
    "           'get_files': get_files(path + os.sep + 'train' + os.sep + 'pos')[:10],\n",
    "           'get_true_labels_pos': list(get_true_labels(get_files(path + os.sep + 'train' + os.sep + 'pos')[:5])),\n",
    "           'get_true_labels_neg': list(get_true_labels(get_files(path + os.sep + 'train' + os.sep + 'neg')[:5])),\n",
    "           'tokenize': tokenize('Hi-there-what_is UP????'),\n",
    "           'tokenize_punct': tokenize_with_punct('Hi-there-what_is UP????'),\n",
    "           'tokenize_not': tokenize_with_not('Hi-that is not cool . at all . not'),\n",
    "           'vec': sorted(do_vectorize(get_files(path + os.sep + 'train' + os.sep + 'pos')[:10])[0][8].nonzero()[1].tolist())[:10],\n",
    "           'vec_nonbinary': sorted(do_vectorize(get_files(path + os.sep + 'train' +\n",
    "                                                         os.sep + 'pos')[:10], binary=False)[0][8].data)[::-1][:10],\n",
    "           'cv10': '%.4f' % do_cross_validation(X[:100], y[:100], verbose=False, n_folds=10),\n",
    "           'cv3': '%.4f' % do_cross_validation(X[:100], y[:100], verbose=False, n_folds=3),\n",
    "           'nfolds_expt': ['%.4f' % v for v in compare_n_folds(filenames, y)],\n",
    "           'binary_expt': ['%.4f' % v for v in compare_binary(filenames, y)],\n",
    "           'tokenizer_expt': ['%.4f' % v for v in tokenizer_expt(filenames, y)],\n",
    "           'mindf_expt': ['%.4f' % v for v in min_df_expt(filenames, y)],\n",
    "           'maxdf_expt': ['%.4f' % v for v in max_df_expt(filenames, y)],\n",
    "           'top_coef': get_top_coefficients(clf, vec, n=3),\n",
    "           'rem_feat': '%.4f' % accuracy_score(train_after_removing_features(X.copy(), y, vec, ['worst']).predict(X_test), y_test),\n",
    "          },\n",
    "          outf, indent=2, sort_keys=True)\n",
    "outf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
